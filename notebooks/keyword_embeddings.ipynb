{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding Analysis\n",
    "\n",
    "One of the key innovations of the Transformers architecture is that token embeddings are _affected_ by nearby tokens (e.g., others words in the sentence). This notebook will demonstrate this effect by analyzing single keywords and comparing the output embedding vectors for the keyword from multiple sentences containing the example keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import torch.nn as F\n",
    "from typing import List, Tuple\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decoding(tokenizer, encoding:torch.tensor) -> List[Tuple[int, str]]:\n",
    "    \"\"\"Show encoded/decoded pairs for example sentence.\"\"\"\n",
    "    return [(_enc.item(), tokenizer.decode(_enc)) for _enc in encoding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = DistilBertModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords and Example Text\n",
    "\n",
    "We set the keyword and create example sentences containing the keyword. Notice in the example sentences below the different _ways_ in which the `keyword` is used. At the end of this notebook, we will compare the individual embeddings for the `keyword` from each of the example sentences. We expect to see a more _similar_ embedding if the `keyword` is used in a similar way between any pair of sentences. For instance, keep in mind examples `examples[0]` and `examples[3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword id: 4405\n"
     ]
    }
   ],
   "source": [
    "# set keyword\n",
    "keyword = \"pilot\"\n",
    "keyword_id = tokenizer.encode(keyword)[1]\n",
    "print('keyword id:', keyword_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create examples where the above keyword is used in different forms\n",
    "examples = [\n",
    "    \"Attention passengers, this is the pilot speaking. Please prepare for landing.\",             # - *flight-related\n",
    "    \"The tv show was funny but it didn't get approved after the pilot.\",                         # - tv show/pilot\n",
    "    \"So, are you happy with your honda pilot? How does it handle the rough roads around here?\",  # - honda pilot\n",
    "    \"Even though the flight was bumpy, I trused the pilot had everything under control.\",        # - *flight-related\n",
    "    \"She was the best pilot the commander had ever seen.\"                                        # - *flighted-related (but less so)\n",
    "]\n",
    "\n",
    "# note: once you have run through this notebook once, return and iteratively change `trused -> trusted` and `bumpy -> turbulent`\n",
    "# and see how the word vector cosine similarity scores change. :O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoding\n",
    "\n",
    "Preprocessing step before input to the model. Each token is translated to the integer id maintained in the `tokenizer` vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 22])\n"
     ]
    }
   ],
   "source": [
    "encodings = tokenizer(examples, padding=True, return_tensors='pt')\n",
    "encodings = encodings['input_ids'] # we aren't interest in attention_masks in this case\n",
    "print(encodings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 3086, 5467, 1010, 2023, 2003, 1996, 4405, 4092, 1012, 3531, 7374,\n",
       "        2005, 4899, 1012,  102,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view encoded tensors from example text (padding makes all examples of equal length)\n",
    "encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(101, '[ C L S ]'),\n",
       " (2130, 'e v e n'),\n",
       " (2295, 't h o u g h'),\n",
       " (1996, 't h e'),\n",
       " (3462, 'f l i g h t'),\n",
       " (2001, 'w a s'),\n",
       " (16906, 'b u m p'),\n",
       " (2100, '# # y'),\n",
       " (1010, ','),\n",
       " (1045, 'i'),\n",
       " (19817, 't r'),\n",
       " (13901, '# # u s e d'),\n",
       " (1996, 't h e'),\n",
       " (4405, 'p i l o t'),\n",
       " (2018, 'h a d'),\n",
       " (2673, 'e v e r y t h i n g'),\n",
       " (2104, 'u n d e r'),\n",
       " (2491, 'c o n t r o l'),\n",
       " (1012, '.'),\n",
       " (102, '[ S E P ]'),\n",
       " (0, '[ P A D ]'),\n",
       " (0, '[ P A D ]')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice how the tokenizer handles example `3`\n",
    "# particularly with the misspelling of \"trusted\" and the work \"bumpy\"\n",
    "show_decoding(tokenizer, encodings[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 15,  9, 13,  5])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices for where `keyword` occurs in each encoded vector\n",
    "keyword_enc_idx = np.where(encodings.numpy() == keyword_id)[1]\n",
    "keyword_enc_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Outputs\n",
    "\n",
    "Input the encoded text examples as a forward-pass to the model. The model will output the embeddings for each token in each text example. We will extract the `keyword` embeddings from each of the sentence outputs to compare the `keyword` representations and how they are affected by their _context_ (i.e., neighbor words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([5, 22, 768])\n"
     ]
    }
   ],
   "source": [
    "# first dim size should equal len(examples)\n",
    "outputs = model(encodings)\n",
    "print('output shape:', outputs[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 768])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2736, -0.1543,  0.0635,  ...,  0.0185,  0.4955,  0.3776],\n",
       "        [ 0.3556,  0.3899,  0.3734,  ..., -0.0779,  0.2457, -0.2127],\n",
       "        [-0.0223,  0.0153,  0.3945,  ...,  0.0511,  0.2932,  0.0463],\n",
       "        ...,\n",
       "        [ 0.0386, -0.3837,  0.0909,  ..., -0.3653,  0.6322, -0.0575],\n",
       "        [ 0.0066,  0.2584,  0.1227,  ...,  0.2462,  0.1527,  0.0671],\n",
       "        [ 0.6849,  0.1757, -0.3934,  ...,  0.1302, -0.3551, -0.3675]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embeddings for `keyword` in each of the sentence outputs\n",
    "keyword_embeddings = torch.stack([outputs[0][i][keyword_enc_idx[i]] for i in range(len(examples))])\n",
    "keyword_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0386, -0.3837,  0.0909,  0.0236,  0.1591,  0.0252, -0.3695,  0.3892,\n",
       "         0.3110, -0.6666], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example embedding for `keyword` from example text `i` (shortened for print-out)\n",
    "keyword_embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3484, -0.5333,  0.0284,  0.2435, -0.2398, -0.2844,  0.2530,  0.2528,\n",
       "         0.2653, -0.0074], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_embeddings[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embedding for Keyword Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pilot'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create single token sentence; this is something of a _control_ vector\n",
    "base_keyword = f\"{keyword}\"\n",
    "base_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - first and last `id` will be beginning and end of sentence tokens\n",
    "base_encoding = tokenizer(base_keyword, return_tensors='pt')\n",
    "base_encoding = base_encoding['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass - get token embedding\n",
    "base_output = model(base_encoding)\n",
    "base_embedding = base_output[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0967, -0.0604, -0.1340, -0.0524,  0.2880,  0.0868, -0.0932, -0.0259,\n",
       "         0.6041, -0.8347], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_embedding[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Between Keyword Embeddings \n",
    "\n",
    "\\*including the `base_embedding`\n",
    "\n",
    "Based on the examples, we expect the keyword embeddings contained in sentences related to a \"pilot\" to be more similar to each other than keyword embeddings in other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = F.CosineSimilarity(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.6127, 0.7506, 0.8833, 0.8510], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# compare cosine similarity between example #1 and all others....\n",
    "sim_scores = cos(keyword_embeddings[0].unsqueeze(dim=0), keyword_embeddings)\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target example: Attention passengers, this is the pilot speaking. Please prepare for landing.\n",
      "\n",
      "example: 'Attention passengers, this is the pilot speaking. Please prepare for landing.'\n",
      "score: 1.000\n",
      "-------------------------------------------------- \n",
      "\n",
      "example: 'The tv show was funny but it didn't get approved after the pilot.'\n",
      "score: 0.613\n",
      "-------------------------------------------------- \n",
      "\n",
      "example: 'So, are you happy with your honda pilot? How does it handle the rough roads around here?'\n",
      "score: 0.751\n",
      "-------------------------------------------------- \n",
      "\n",
      "example: 'Even though the flight was bumpy, I trused the pilot had everything under control.'\n",
      "score: 0.883\n",
      "-------------------------------------------------- \n",
      "\n",
      "example: 'She was the best pilot the commander had ever seen.'\n",
      "score: 0.851\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the sim-scores besides text to see clearly...\n",
    "print(f\"target example: {examples[0]}\\n\")\n",
    "\n",
    "for example, score in zip(examples, sim_scores.tolist()):\n",
    "    print(f\"example: '{example}'\")\n",
    "    print(f\"score: {score:.3f}\")\n",
    "    print( \"-\" * 50, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6686, 0.5095, 0.5919, 0.6764, 0.6742], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare all sentence-based keyword embeddings with the `base_embedding`\n",
    "# we don't see the same degree of separation as above...\n",
    "cos(keyword_embeddings, base_embedding.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274bd73297121532e2eb0d721b37cb8759597126faa6ea41d61bfc5df36e6486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
