{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embedding Analysis\n",
    "\n",
    "One of the key innovations of the Transformers architecture is that token embeddings are _affected_ by nearby tokens (e.g., others words in the sentence). This notebook will demonstrate this effect by analyzing single keywords and comparing the output embedding vectors for the keyword from multiple sentences containing the example keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/371702/projects/sundry-llm/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import torch.nn as F\n",
    "from typing import List, Tuple\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_decoding(tokenizer, encoding:torch.tensor) -> List[Tuple[int, str]]:\n",
    "    \"\"\"Show encoded/decoded pairs for example sentence.\"\"\"\n",
    "    return [(_enc.item(), tokenizer.decode(_enc)) for _enc in encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords and Example Text\n",
    "\n",
    "We set the keyword and create example sentences containing the keyword. Notice in the example sentences below the different _ways_ in which the `keyword` is used. At the end of this notebook, we will compare the individual embeddings for the `keyword` from each of the example sentences. We expect to see a more _similar_ embedding if the `keyword` is used in a similar way between any pair of sentences. For instance, keep in mind examples `examples[0]` and `examples[3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword id: 4405\n"
     ]
    }
   ],
   "source": [
    "# set keyword\n",
    "keyword = \"pilot\"\n",
    "keyword_id = tokenizer.encode(keyword)[1]\n",
    "print('keyword id:', keyword_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create examples where the above keyword is used in different forms\n",
    "examples = [\n",
    "    \"Attention passengers, this is the pilot speaking. Please prepare for landing.\", # <- flight-related\n",
    "    \"The tv show was funny but it didn't get approved after the pilot.\", \n",
    "    \"So, are you happy with your honda pilot? How does it handle the rough roads around here?\", \n",
    "    \"Even though the flight was turbulent, I trusted the pilot had everything under control.\", # <- flight-related\n",
    "    \"She was the best pilot the commander had ever seen.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoding\n",
    "\n",
    "Preprocessing step before input to the model. Each token is translated to the integer id maintained in the `tokenizer` vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 22])\n"
     ]
    }
   ],
   "source": [
    "encodings = tokenizer(examples, padding=True, return_tensors='pt')\n",
    "encodings = encodings['input_ids'] # we aren't interest in attention_masks in this case\n",
    "print(encodings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 3086, 5467, 1010, 2023, 2003, 1996, 4405, 4092, 1012, 3531, 7374,\n",
       "        2005, 4899, 1012,  102,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view encoded tensors from example text (padding makes all examples of equal length)\n",
    "encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(101, '[ C L S ]'),\n",
       " (2130, 'e v e n'),\n",
       " (2295, 't h o u g h'),\n",
       " (1996, 't h e'),\n",
       " (3462, 'f l i g h t'),\n",
       " (2001, 'w a s'),\n",
       " (22609, 't u r b u l e n t'),\n",
       " (1010, ','),\n",
       " (1045, 'i'),\n",
       " (9480, 't r u s t e d'),\n",
       " (1996, 't h e'),\n",
       " (4405, 'p i l o t'),\n",
       " (2018, 'h a d'),\n",
       " (2673, 'e v e r y t h i n g'),\n",
       " (2104, 'u n d e r'),\n",
       " (2491, 'c o n t r o l'),\n",
       " (1012, '.'),\n",
       " (102, '[ S E P ]'),\n",
       " (0, '[ P A D ]'),\n",
       " (0, '[ P A D ]'),\n",
       " (0, '[ P A D ]'),\n",
       " (0, '[ P A D ]')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice how the tokenizer handles example `3`\n",
    "# particularly with the misspelling of \"trusted\" and the work \"bumpy\"\n",
    "show_decoding(tokenizer, encodings[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 15,  9, 11,  5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices for where `keyword` occurs in each encoded vector\n",
    "keyword_enc_idx = np.where(encodings.numpy() == keyword_id)[1]\n",
    "keyword_enc_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Outputs\n",
    "\n",
    "Input the encoded text examples as a forward-pass to the model. The model will output the embeddings for each token in each text example. We will extract the `keyword` embeddings from each of the sentence outputs to compare the `keyword` representations and how they are affected by their _context_ (i.e., neighbor words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([5, 22, 768])\n"
     ]
    }
   ],
   "source": [
    "# first dim size should equal len(examples)\n",
    "outputs = model(encodings)\n",
    "print('output shape:', outputs[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 22, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2736, -0.1543,  0.0635,  ...,  0.0185,  0.4955,  0.3776],\n",
       "         [ 0.3556,  0.3899,  0.3734,  ..., -0.0779,  0.2457, -0.2127],\n",
       "         [-0.0223,  0.0153,  0.3945,  ...,  0.0511,  0.2932,  0.0463],\n",
       "         ...,\n",
       "         [ 0.3637, -0.1927,  0.4301,  ...,  0.0364,  0.3203, -0.3774],\n",
       "         [ 0.4107, -0.2260,  0.4248,  ...,  0.0392,  0.3263, -0.4284],\n",
       "         [ 0.4081, -0.2384,  0.4259,  ...,  0.0639,  0.3257, -0.4584]],\n",
       "\n",
       "        [[-0.0736, -0.3944,  0.1900,  ..., -0.1812,  0.5740,  0.2573],\n",
       "         [ 0.0144, -0.7304, -0.4040,  ..., -0.1761,  0.8622, -0.2593],\n",
       "         [ 0.0136, -0.6067,  0.0610,  ..., -0.2159,  0.7598, -0.2419],\n",
       "         ...,\n",
       "         [ 0.2783, -0.3372,  0.3197,  ...,  0.1241,  0.2205, -0.1912],\n",
       "         [ 0.3623, -0.3474,  0.3242,  ...,  0.1781,  0.2146, -0.2292],\n",
       "         [ 0.3049, -0.4622,  0.1602,  ...,  0.2063,  0.2096, -0.1351]],\n",
       "\n",
       "        [[ 0.0841,  0.0536, -0.1024,  ..., -0.1595,  0.4923,  0.1829],\n",
       "         [ 0.2789, -0.5166,  0.1365,  ...,  0.3170,  0.9920,  0.0474],\n",
       "         [-0.0563,  0.0307,  0.2355,  ..., -0.2220,  0.3069, -0.3143],\n",
       "         ...,\n",
       "         [ 0.0526,  0.2200,  0.0575,  ..., -0.5552,  0.2739, -0.3782],\n",
       "         [-0.1393, -0.4757, -0.6921,  ..., -0.0898,  0.3495, -0.0546],\n",
       "         [ 0.7501,  0.0853, -0.3856,  ...,  0.0573, -0.2889, -0.5703]],\n",
       "\n",
       "        [[-0.0387,  0.0173,  0.0494,  ...,  0.0239,  0.2970,  0.2664],\n",
       "         [-0.7979,  0.1537, -0.1103,  ...,  0.0584,  0.5276,  0.1024],\n",
       "         [-1.0457,  0.5427,  0.0796,  ..., -0.0878,  0.1326,  0.4256],\n",
       "         ...,\n",
       "         [ 0.1900,  0.0510,  0.2434,  ...,  0.0546,  0.0716, -0.1348],\n",
       "         [ 0.2837,  0.0394,  0.2375,  ...,  0.1186,  0.0741, -0.1420],\n",
       "         [ 0.2119, -0.1023,  0.0612,  ...,  0.2553,  0.0743, -0.0069]],\n",
       "\n",
       "        [[-0.4049, -0.2680, -0.0783,  ...,  0.1105,  0.5248,  0.1833],\n",
       "         [-0.2878, -0.6372, -0.3262,  ..., -0.1177,  0.4682, -0.1229],\n",
       "         [-0.5753, -0.5961, -0.1953,  ..., -0.1976,  0.5020,  0.1421],\n",
       "         ...,\n",
       "         [ 0.3296, -0.2749,  0.3736,  ...,  0.0712,  0.3950, -0.4398],\n",
       "         [ 0.3921, -0.2902,  0.3657,  ...,  0.0734,  0.4200, -0.5151],\n",
       "         [ 0.3239, -0.3599,  0.3200,  ...,  0.1078,  0.4359, -0.5052]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embeddings for `keyword` in each of the sentence outputs\n",
    "keyword_embeddings = torch.stack([outputs[0][i][keyword_enc_idx[i]] for i in range(len(examples))])\n",
    "keyword_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0386, -0.3837,  0.0909,  0.0236,  0.1591,  0.0252, -0.3695,  0.3892,\n",
       "         0.3110, -0.6666], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example embedding for `keyword` from example text `i` (shortened for print-out)\n",
    "keyword_embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3484, -0.5333,  0.0284,  0.2435, -0.2398, -0.2844,  0.2531,  0.2528,\n",
       "         0.2653, -0.0074], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_embeddings[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embedding for Keyword Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pilot'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create single token sentence\n",
    "base_keyword = f\"{keyword}\"\n",
    "base_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - first and last `id` will be beginning and end of sentence tokens\n",
    "base_encoding = tokenizer(base_keyword, return_tensors='pt')\n",
    "base_encoding = base_encoding['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass - get token embedding\n",
    "base_output = model(base_encoding)\n",
    "base_embedding = base_output[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0967, -0.0604, -0.1340, -0.0524,  0.2880,  0.0868, -0.0932, -0.0259,\n",
       "         0.6041, -0.8347], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_embedding[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Between Keyword Embeddings \n",
    "\n",
    "\\*including the `base_embedding`\n",
    "\n",
    "Based on the examples, we expect the keyword embeddings contained in sentences related to a \"pilot\" to be more similar to each other than keyword embeddings in other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = F.CosineSimilarity(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = torch.stack([\n",
    "    cos(keyword_embeddings, keyword_embeddings[i]) \n",
    "    for i in range(len(examples))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6127, 0.7506, 0.9188, 0.8510],\n",
       "        [0.6127, 1.0000, 0.5606, 0.5833, 0.6129],\n",
       "        [0.7506, 0.5606, 1.0000, 0.7733, 0.7424],\n",
       "        [0.9188, 0.5833, 0.7733, 1.0000, 0.8347],\n",
       "        [0.8510, 0.6129, 0.7424, 0.8347, 1.0000]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9188, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# important similarity scores based on example texts\n",
    "sim_scores[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6686, 0.5095, 0.5919, 0.6675, 0.6742], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare all sentence-based keyword embeddings with the `base_embedding`\n",
    "cos(keyword_embeddings, base_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Specific Terminology\n",
    "\n",
    "When we ask the \"off-the-shelf\" pretrained tokenizers and models to utilize domain specific terminology, we begin to encounter various _types_ of issues, such as:\n",
    "\n",
    "- Out of Vocabulary terms\n",
    "- Homonyms (i.e. words with same spelling but different meanings)\n",
    "- Breaking of alpha-numeric references, codes, etc. (e.g., AMM reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe how the tokenizer regards nacelles, ac, and the amm reference\n",
    "example = \"inspected right side nacelles for ac 99999 per manual reference 123-456-789.\"\n",
    "example_enc = tokenizer(example, return_tensors='pt')['input_ids'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(101, '[ C L S ]'),\n",
       " (20456, 'i n s p e c t e d'),\n",
       " (2157, 'r i g h t'),\n",
       " (2217, 's i d e'),\n",
       " (6583, 'n a'),\n",
       " (29109, '# # c e l'),\n",
       " (4244, '# # l e s'),\n",
       " (2005, 'f o r'),\n",
       " (9353, 'a c'),\n",
       " (25897, '9 9 9'),\n",
       " (2683, '# # 9'),\n",
       " (2683, '# # 9'),\n",
       " (2566, 'p e r'),\n",
       " (6410, 'm a n u a l'),\n",
       " (4431, 'r e f e r e n c e'),\n",
       " (13138, '1 2 3'),\n",
       " (1011, '-'),\n",
       " (3429, '4 5'),\n",
       " (2575, '# # 6'),\n",
       " (1011, '-'),\n",
       " (6275, '7 8'),\n",
       " (2683, '# # 9'),\n",
       " (1012, '.'),\n",
       " (102, '[ S E P ]')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer vocab does not have entry for \"nacelles\", breaks up ac number & manual reference\n",
    "show_decoding(tokenizer, example_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274bd73297121532e2eb0d721b37cb8759597126faa6ea41d61bfc5df36e6486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
